{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可以更新最近上傳的內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import re\n",
    "import urllib3\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "\n",
    "class ArticleScraper:\n",
    "    def __init__(self, scan_mode=\"recent\", data_file=\"articles.xlsx\"):\n",
    "        \"\"\"初始化爬蟲設定\n",
    "        \n",
    "        Args:\n",
    "            scan_mode (str): 掃描模式 (\"recent\", \"all\", \"range\")\n",
    "            data_file (str): 儲存資料的Excel檔案名稱\n",
    "        \"\"\"\n",
    "        self.SETTINGS = {\n",
    "            'BASE_URL': \"https://real-estate.get.com.tw/Columns/\",\n",
    "            'TARGET_AUTHORS': [\"曾榮耀\", \"許文昌\", \"蘇偉強\"],\n",
    "            'JOURNAL_PARAMS': {\n",
    "                \"no\": \"1282\",\n",
    "                \"pno\": \"51121\"\n",
    "            },\n",
    "            'PERFORMANCE': {\n",
    "                'RETRY_DELAY': 3,\n",
    "                'REQUEST_INTERVAL': 1.5,\n",
    "                'MAX_RETRIES': 5,\n",
    "                'TIMEOUTS': {\n",
    "                    'CONNECT': 10,\n",
    "                    'READ': 30,\n",
    "                    'TOTAL': 40\n",
    "                }\n",
    "            },\n",
    "            'SCAN_MODES': {\n",
    "                'recent': {\n",
    "                    'days': 30,\n",
    "                    'batch_size': 50,\n",
    "                    'max_workers': 4\n",
    "                },\n",
    "                'all': {\n",
    "                    'batch_size': 100,\n",
    "                    'max_workers': 8,\n",
    "                    'article_ranges': [\n",
    "                        {\n",
    "                            \"start\": 900000,\n",
    "                            \"end\": 915000,\n",
    "                            \"description\": \"新年份範圍\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"start\": 409187,\n",
    "                            \"end\": 421516,\n",
    "                            \"description\": \"早期年份範圍\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                'range': {\n",
    "                    'batch_size': 75,\n",
    "                    'max_workers': 6\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # 初始化基本屬性\n",
    "        self.scan_mode = scan_mode\n",
    "        if scan_mode not in self.SETTINGS['SCAN_MODES']:\n",
    "            raise ValueError(f\"不支援的掃描模式: {scan_mode}\")\n",
    "\n",
    "        self.mode_settings = self.SETTINGS['SCAN_MODES'][scan_mode]\n",
    "        self.data_file = Path(data_file)\n",
    "\n",
    "        # 初始化URL和參數\n",
    "        self.detail_url = f\"{self.SETTINGS['BASE_URL']}detail.aspx\"\n",
    "        self.journal_url = f\"{self.SETTINGS['BASE_URL']}journal.aspx\"\n",
    "        self.journal_params = self.SETTINGS['JOURNAL_PARAMS'].copy()\n",
    "        self.target_authors = self.SETTINGS['TARGET_AUTHORS']\n",
    "\n",
    "        # 初始化效能參數\n",
    "        self.request_interval = self.SETTINGS['PERFORMANCE']['REQUEST_INTERVAL']\n",
    "        self.retry_delay = self.SETTINGS['PERFORMANCE']['RETRY_DELAY']\n",
    "        self.max_retries = self.SETTINGS['PERFORMANCE']['MAX_RETRIES']\n",
    "        self.timeouts = self.SETTINGS['PERFORMANCE']['TIMEOUTS'].copy()\n",
    "\n",
    "        # 設定路徑\n",
    "        self.base_dir = Path('data')\n",
    "        self.images_dir = self.base_dir / 'images'\n",
    "        self.logs_dir = self.base_dir / 'logs'\n",
    "        self.failed_image_path = self.base_dir / 'failed.jpg'\n",
    "\n",
    "        # 建立必要的目錄\n",
    "        self._create_directories()\n",
    "\n",
    "        # 設定 logger\n",
    "        self._setup_logger()\n",
    "\n",
    "        # 初始化 session\n",
    "        self.session = self._setup_session()\n",
    "\n",
    "        # 載入已處理的文章\n",
    "        self.processed_articles = self._load_processed_articles()\n",
    "\n",
    "        # 根據掃描模式設定參數\n",
    "        self._setup_scan_mode()\n",
    "\n",
    "        # 設定最後請求時間\n",
    "        self.last_request_time = 0\n",
    "        \n",
    "\n",
    "    def _create_directories(self):\n",
    "        \"\"\"創建必要的目錄結構\"\"\"\n",
    "        for directory in [self.base_dir, self.images_dir, self.logs_dir]:\n",
    "            directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 創建預設的失敗圖片\n",
    "        if not self.failed_image_path.exists():\n",
    "            try:\n",
    "                img = Image.new('RGB', (400, 100), color='white')\n",
    "                d = ImageDraw.Draw(img)\n",
    "                d.text((10, 40), \"Image Download Failed\", fill='black')\n",
    "                img.save(str(self.failed_image_path))  # 轉換為字符串路徑\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"創建失敗圖片時發生錯誤: {str(e)}\")\n",
    "                self.failed_image_path.touch()\n",
    "\n",
    "\n",
    "    def _setup_logger(self):\n",
    "        \"\"\"設定日誌系統\"\"\"\n",
    "        self.logger = logging.getLogger('ArticleScraper')\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "        # 確保處理器不會重複添加\n",
    "        if not self.logger.handlers:\n",
    "            # 創建日誌檔案\n",
    "            log_file = self.logs_dir / \\\n",
    "                f\"scraper_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "\n",
    "            # 設定處理器\n",
    "            file_handler = logging.FileHandler(str(log_file), encoding='utf-8')\n",
    "            console_handler = logging.StreamHandler()\n",
    "\n",
    "            # 設定格式\n",
    "            formatter = logging.Formatter(\n",
    "                '%(asctime)s - %(levelname)s - %(message)s')\n",
    "            file_handler.setFormatter(formatter)\n",
    "            console_handler.setFormatter(formatter)\n",
    "\n",
    "            # 添加處理器\n",
    "            self.logger.addHandler(file_handler)\n",
    "            self.logger.addHandler(console_handler)\n",
    "\n",
    "\n",
    "    def _setup_session(self):\n",
    "        \"\"\"設定並返回requests session\"\"\"\n",
    "        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "        session = requests.Session()\n",
    "        session.headers.update({\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',\n",
    "            'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1'\n",
    "        })\n",
    "        return session\n",
    "\n",
    "\n",
    "    def _load_processed_articles(self):\n",
    "        \"\"\"載入已處理的文章編號集合\"\"\"\n",
    "        processed = set()\n",
    "        if self.data_file.exists():\n",
    "            try:\n",
    "                df = pd.read_excel(str(self.data_file))\n",
    "                if '文章編號' in df.columns:\n",
    "                    processed = set(df['文章編號'].astype(str))\n",
    "                self.logger.info(f\"已載入 {len(processed)} 篇已處理文章\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"載入已處理文章時發生錯誤: {str(e)}\")\n",
    "        return processed\n",
    "\n",
    "\n",
    "    def _setup_scan_mode(self):\n",
    "        \"\"\"根據掃描模式設定相關參數\"\"\"\n",
    "        self.batch_size = self.mode_settings['batch_size']\n",
    "        self.max_workers = self.mode_settings['max_workers']\n",
    "\n",
    "        now = datetime.now()\n",
    "        if self.scan_mode == 'recent':\n",
    "            self.start_date = now - timedelta(days=self.mode_settings['days'])\n",
    "            self.end_date = now\n",
    "        elif self.scan_mode == 'range':\n",
    "            # 需要外部設定日期範圍\n",
    "            self.start_date = None\n",
    "            self.end_date = None\n",
    "        else:  # 'all' mode\n",
    "            self.start_date = datetime(2016, 1, 1)\n",
    "            self.end_date = now\n",
    "\n",
    "        self.logger.info(f\"掃描模式: {self.scan_mode}\")\n",
    "        if self.start_date and self.end_date:\n",
    "            self.logger.info(f\"日期範圍: {self.start_date.date()} 到 {\n",
    "                            self.end_date.date()}\")\n",
    "\n",
    "\n",
    "    def wait_between_requests(self):\n",
    "        \"\"\"控制請求間隔\"\"\"\n",
    "        current_time = time.time()\n",
    "        elapsed = current_time - self.last_request_time\n",
    "        if elapsed < self.request_interval:\n",
    "            time.sleep(self.request_interval - elapsed)\n",
    "        self.last_request_time = time.time()\n",
    "\n",
    "\n",
    "    def set_date_range(self, start_date: datetime, end_date: datetime):\n",
    "        \"\"\"設定掃描的日期範圍\"\"\"\n",
    "        if self.scan_mode != 'range':\n",
    "            raise ValueError(\"只有在 'range' 模式下才能設定日期範圍\")\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.logger.info(f\"設定日期範圍: {start_date.date()} 到 {end_date.date()}\")\n",
    "        \n",
    "        \n",
    "    def make_request(self, url: str, params: Optional[Dict] = None, method: str = 'get',\n",
    "                    retry_count: int = 0) -> Optional[requests.Response]:\n",
    "        \"\"\"發送 HTTP 請求並處理重試邏輯\n",
    "        \n",
    "        Args:\n",
    "            url: 請求URL\n",
    "            params: URL參數\n",
    "            method: HTTP方法 ('get' 或 'post')\n",
    "            retry_count: 當前重試次數\n",
    "        \n",
    "        Returns:\n",
    "            Response對象或None（如果請求失敗）\n",
    "        \"\"\"\n",
    "        if retry_count >= self.max_retries:\n",
    "            self.logger.error(f\"達到最大重試次數 ({self.max_retries})\")\n",
    "            return None\n",
    "\n",
    "        self.wait_between_requests()\n",
    "\n",
    "        try:\n",
    "            if method.lower() == 'post':\n",
    "                response = self.session.post(\n",
    "                    url,\n",
    "                    params=params,\n",
    "                    verify=False,\n",
    "                    timeout=(self.timeouts['CONNECT'], self.timeouts['READ'])\n",
    "                )\n",
    "            else:\n",
    "                response = self.session.get(\n",
    "                    url,\n",
    "                    params=params,\n",
    "                    verify=False,\n",
    "                    timeout=(self.timeouts['CONNECT'], self.timeouts['READ'])\n",
    "                )\n",
    "\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            self.logger.warning(\n",
    "                f\"請求失敗 (重試 {retry_count + 1}/{self.max_retries}): {str(e)}\")\n",
    "            time.sleep(self.retry_delay * (retry_count + 1))  # 指數退避\n",
    "            return self.make_request(url, params, method, retry_count + 1)\n",
    "\n",
    "\n",
    "    def parse_article_list(self, html_content: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"解析文章列表頁面\n",
    "        \n",
    "        Args:\n",
    "            html_content: HTML內容\n",
    "        \n",
    "        Returns:\n",
    "            文章資訊列表\n",
    "        \"\"\"\n",
    "        articles = []\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            article_elements = soup.select('div.article-item')  # 根據實際HTML結構調整\n",
    "\n",
    "            for element in article_elements:\n",
    "                try:\n",
    "                    article_info = {\n",
    "                        '文章編號': element.get('data-article-id', '').strip(),\n",
    "                        '標題': element.select_one('.title').text.strip(),\n",
    "                        '作者': element.select_one('.author').text.strip(),\n",
    "                        '發布日期': element.select_one('.date').text.strip(),\n",
    "                        '摘要': element.select_one('.summary').text.strip()\n",
    "                    }\n",
    "\n",
    "                    # 檢查必要欄位\n",
    "                    if not all(article_info.values()):\n",
    "                        continue\n",
    "\n",
    "                    # 轉換日期格式\n",
    "                    try:\n",
    "                        date_str = article_info['發布日期']\n",
    "                        article_info['發布日期'] = datetime.strptime(\n",
    "                            date_str, '%Y-%m-%d')\n",
    "                    except ValueError:\n",
    "                        self.logger.warning(f\"日期格式錯誤: {date_str}\")\n",
    "                        continue\n",
    "\n",
    "                    articles.append(article_info)\n",
    "\n",
    "                except Exception as e:\n",
    "                    self.logger.warning(f\"解析文章元素時發生錯誤: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"解析文章列表時發生錯誤: {str(e)}\")\n",
    "\n",
    "        return articles\n",
    "\n",
    "\n",
    "    def parse_article_detail(self, html_content: str, article_no: str) -> Dict[str, Any]:\n",
    "        \"\"\"解析文章詳細內容頁面\n",
    "        \n",
    "        Args:\n",
    "            html_content: HTML內容\n",
    "            article_no: 文章編號\n",
    "        \n",
    "        Returns:\n",
    "            文章詳細資訊字典\n",
    "        \"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(html_content, 'html.parser')\n",
    "            article_data = {\n",
    "                '文章編號': article_no,\n",
    "                '標題': '',\n",
    "                '作者': '',\n",
    "                '發布日期': '',\n",
    "                '內文': '',\n",
    "                '圖片連結': []\n",
    "            }\n",
    "\n",
    "            # 解析標題\n",
    "            title_element = soup.select_one('h1.article-title')\n",
    "            if title_element:\n",
    "                article_data['標題'] = title_element.text.strip()\n",
    "\n",
    "            # 解析作者\n",
    "            author_element = soup.select_one('div.author-info')\n",
    "            if author_element:\n",
    "                article_data['作者'] = author_element.text.strip()\n",
    "\n",
    "            # 解析發布日期\n",
    "            date_element = soup.select_one('div.publish-date')\n",
    "            if date_element:\n",
    "                date_str = date_element.text.strip()\n",
    "                try:\n",
    "                    article_data['發布日期'] = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "                except ValueError:\n",
    "                    self.logger.warning(f\"文章 {article_no} 日期格式錯誤: {date_str}\")\n",
    "\n",
    "            # 解析內文\n",
    "            content_element = soup.select_one('div.article-content')\n",
    "            if content_element:\n",
    "                # 移除不需要的元素\n",
    "                for element in content_element.select('script, style, iframe'):\n",
    "                    element.decompose()\n",
    "\n",
    "                article_data['內文'] = content_element.get_text(strip=True)\n",
    "\n",
    "            # 解析圖片連結\n",
    "            image_elements = soup.select('div.article-content img')\n",
    "            for img in image_elements:\n",
    "                src = img.get('src', '')\n",
    "                if src:\n",
    "                    if not src.startswith(('http://', 'https://')):\n",
    "                        src = urllib.parse.urljoin(self.SETTINGS['BASE_URL'], src)\n",
    "                    article_data['圖片連結'].append(src)\n",
    "\n",
    "            return article_data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"解析文章 {article_no} 詳細內容時發生錯誤: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def download_image(self, url: str, save_path: Path) -> bool:\n",
    "        \"\"\"下載並保存圖片\n",
    "        \n",
    "        Args:\n",
    "            url: 圖片URL\n",
    "            save_path: 保存路徑\n",
    "        \n",
    "        Returns:\n",
    "            是否成功下載\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.make_request(url)\n",
    "            if not response:\n",
    "                return False\n",
    "\n",
    "            # 檢查內容類型\n",
    "            content_type = response.headers.get('content-type', '')\n",
    "            if not content_type.startswith('image/'):\n",
    "                self.logger.warning(f\"非圖片內容類型: {content_type}\")\n",
    "                return False\n",
    "\n",
    "            # 保存圖片\n",
    "            with open(save_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"下載圖片失敗 ({url}): {str(e)}\")\n",
    "            return False\n",
    "        \n",
    "\n",
    "    def save_article_markdown(self, article_data: Dict) -> None:\n",
    "        \"\"\"將文章保存為Markdown格式\n",
    "        \n",
    "        Args:\n",
    "            article_data: 文章資料字典\n",
    "        \"\"\"\n",
    "        try:\n",
    "            article_no = article_data['文章編號']\n",
    "            # 清理標題中的非法字符\n",
    "            title = re.sub(r'[<>:\"/\\\\|?*]', '', article_data['標題'])[:50]\n",
    "\n",
    "            # 建立文章目錄\n",
    "            article_dir = self.base_dir / article_no\n",
    "            article_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # 準備Markdown內容\n",
    "            markdown_content = [\n",
    "                f\"# {article_data['標題']}\",\n",
    "                \"\",\n",
    "                f\"作者：{article_data['作者']}\",\n",
    "                f\"發布日期：{article_data['發布日期'].strftime('%Y-%m-%d')}\",\n",
    "                f\"文章編號：{article_no}\",\n",
    "                \"\",\n",
    "                \"## 內文\",\n",
    "                \"\",\n",
    "                article_data['內文'],\n",
    "                \"\",\n",
    "                \"## 圖片\",\n",
    "                \"\"\n",
    "            ]\n",
    "\n",
    "            # 處理圖片\n",
    "            for i, img_url in enumerate(article_data['圖片連結'], 1):\n",
    "                img_filename = f\"image_{i}.jpg\"\n",
    "                img_path = article_dir / img_filename\n",
    "\n",
    "                if self.download_image(img_url, img_path):\n",
    "                    markdown_content.append(f\"![圖片{i}]({img_filename})\")\n",
    "                else:\n",
    "                    markdown_content.append(f\"![下載失敗的圖片{i}](failed_image.jpg)\")\n",
    "                markdown_content.append(\"\")\n",
    "\n",
    "            # 保存Markdown文件\n",
    "            markdown_path = article_dir / f\"{title}.md\"\n",
    "            with open(markdown_path, 'w', encoding='utf-8') as f:\n",
    "                f.write('\\n'.join(markdown_content))\n",
    "\n",
    "            self.logger.info(f\"已保存文章 {article_no} 的Markdown文件\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"保存文章 {article_no} Markdown時發生錯誤: {str(e)}\")\n",
    "\n",
    "\n",
    "    def save_to_excel(self, articles: List[Dict]) -> None:\n",
    "        \"\"\"將文章資料保存到Excel\n",
    "        \n",
    "        Args:\n",
    "            articles: 文章資料列表\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 準備DataFrame\n",
    "            df = pd.DataFrame(articles)\n",
    "\n",
    "            # 如果文件已存在，讀取並合併\n",
    "            if self.data_file.exists():\n",
    "                existing_df = pd.read_excel(str(self.data_file))\n",
    "                # 使用文章編號作為索引合併\n",
    "                df = pd.concat([existing_df, df]).drop_duplicates(\n",
    "                    subset=['文章編號'], keep='last')\n",
    "\n",
    "            # 排序並保存\n",
    "            df = df.sort_values('發布日期', ascending=False)\n",
    "            df.to_excel(str(self.data_file), index=False)\n",
    "            self.logger.info(f\"已更新Excel文件，共 {len(df)} 篇文章\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"保存Excel文件時發生錯誤: {str(e)}\")\n",
    "\n",
    "\n",
    "    def process_article(self, article_info: Dict) -> Optional[Dict]:\n",
    "        \"\"\"處理單篇文章\n",
    "        \n",
    "        Args:\n",
    "            article_info: 文章基本資訊\n",
    "        \n",
    "        Returns:\n",
    "            完整的文章資料或None（如果處理失敗）\n",
    "        \"\"\"\n",
    "        article_no = article_info['文章編號']\n",
    "\n",
    "        try:\n",
    "            # 檢查是否已處理\n",
    "            if article_no in self.processed_articles:\n",
    "                self.logger.debug(f\"文章 {article_no} 已處理，跳過\")\n",
    "                return None\n",
    "\n",
    "            # 獲取文章詳細頁面\n",
    "            url = f\"{self.SETTINGS['BASE_URL']}article/{article_no}\"\n",
    "            response = self.make_request(url)\n",
    "            if not response:\n",
    "                return None\n",
    "\n",
    "            # 解析文章詳細內容\n",
    "            article_data = self.parse_article_detail(response.text, article_no)\n",
    "            if not article_data:\n",
    "                return None\n",
    "\n",
    "            # 保存Markdown\n",
    "            self.save_article_markdown(article_data)\n",
    "\n",
    "            return article_data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"處理文章 {article_no} 時發生錯誤: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    def scan_articles(self) -> None:\n",
    "        \"\"\"主要掃描邏輯\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"開始掃描文章...\")\n",
    "            processed_count = 0\n",
    "\n",
    "            # 根據掃描模式設定文章範圍\n",
    "            if self.scan_mode == 'all':\n",
    "                for range_info in self.mode_settings['article_ranges']:\n",
    "                    self.logger.info(f\"掃描範圍: {range_info['description']}\")\n",
    "                    article_numbers = range(range_info['start'], range_info['end'])\n",
    "                    self._process_article_batch(article_numbers)\n",
    "\n",
    "            elif self.scan_mode in ['recent', 'range']:\n",
    "                # 獲取文章列表\n",
    "                page = 1\n",
    "                while True:\n",
    "                    url = f\"{self.SETTINGS['BASE_URL']}list\"\n",
    "                    response = self.make_request(url, params={'page': page})\n",
    "                    if not response:\n",
    "                        break\n",
    "\n",
    "                    articles = self.parse_article_list(response.text)\n",
    "                    if not articles:\n",
    "                        break\n",
    "\n",
    "                    # 檢查日期範圍\n",
    "                    articles = [\n",
    "                        a for a in articles\n",
    "                        if self.start_date <= a['發布日期'] <= self.end_date\n",
    "                    ]\n",
    "\n",
    "                    if not articles:\n",
    "                        break\n",
    "\n",
    "                    # 處理文章批次\n",
    "                    self._process_article_batch(articles)\n",
    "                    processed_count += len(articles)\n",
    "                    page += 1\n",
    "\n",
    "            self.logger.info(f\"掃描完成，共處理 {processed_count} 篇文章\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"掃描過程中發生錯誤: {str(e)}\")\n",
    "\n",
    "\n",
    "    def _process_article_batch(self, articles) -> None:\n",
    "        \"\"\"使用線程池處理文章批次\n",
    "        \n",
    "        Args:\n",
    "            articles: 文章列表或範圍\n",
    "        \"\"\"\n",
    "        processed_articles = []\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            future_to_article = {\n",
    "                executor.submit(self.process_article, article): article\n",
    "                for article in articles\n",
    "            }\n",
    "\n",
    "            for future in tqdm(future_to_article, desc=\"處理文章\"):\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result:\n",
    "                        processed_articles.append(result)\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"處理文章批次時發生錯誤: {str(e)}\")\n",
    "\n",
    "        if processed_articles:\n",
    "            self.save_to_excel(processed_articles)\n",
    "        \n",
    "\n",
    "def main():\n",
    "    \"\"\"主程序入口\"\"\"\n",
    "    import argparse\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # 設定命令行參數\n",
    "    parser = argparse.ArgumentParser(description='文章爬蟲工具')\n",
    "    parser.add_argument(\n",
    "        '--mode',\n",
    "        choices=['recent', 'all', 'range'],\n",
    "        default='recent',\n",
    "        help='掃描模式：recent(最近30天), all(全部), range(指定範圍)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--start-date',\n",
    "        type=str,\n",
    "        help='開始日期 (YYYY-MM-DD)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--end-date',\n",
    "        type=str,\n",
    "        help='結束日期 (YYYY-MM-DD)'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--output',\n",
    "        type=str,\n",
    "        default='articles.xlsx',\n",
    "        help='輸出Excel檔案名稱'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--log-level',\n",
    "        choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'],\n",
    "        default='INFO',\n",
    "        help='日誌級別'\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # 設定日期範圍\n",
    "    if args.mode == 'range':\n",
    "        if not (args.start_date and args.end_date):\n",
    "            print(\"Error: range模式需要指定開始和結束日期\")\n",
    "            return\n",
    "        try:\n",
    "            start_date = datetime.strptime(args.start_date, '%Y-%m-%d')\n",
    "            end_date = datetime.strptime(args.end_date, '%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            print(\"Error: 日期格式錯誤，請使用YYYY-MM-DD格式\")\n",
    "            return\n",
    "    else:\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=30)\n",
    "\n",
    "    # 初始化爬蟲\n",
    "    try:\n",
    "        scraper = ArticleScraper(\n",
    "            scan_mode=args.mode,\n",
    "            data_file=args.output\n",
    "        )\n",
    "\n",
    "        # 設定日誌級別\n",
    "        scraper.logger.setLevel(getattr(logging, args.log_level))\n",
    "\n",
    "        # 開始執行\n",
    "        scraper.scan_articles()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"執行過程中發生錯誤: {str(e)}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
